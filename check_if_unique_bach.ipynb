{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bach Chorales\n",
    "## Comparing Generated Sequences to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_generator.serializers.discrete_time_serializer import DiscreteTimeMidiSerializer\n",
    "import music_generator.utilities.sequence_utils as sequence_utils\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up constants for generation and comparison\n",
    "\n",
    "A single quarter-note four-voice chord would be made up of at least 9 events (4 note-on, 4 note-off, at least 4 wait events if no chaining is required),\n",
    "so a measure of four quarter-note four-voice chords would be a minimum of 36 events.\n",
    "\n",
    "Adding in eigth notes, flourishes, etc. would increase the number of events in a measure.\n",
    "\n",
    "Windows of 100 events are used to compare generated sequences and training sequences. This would generally represent somewhere from one to four measures, depending on note frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializer = DiscreteTimeMidiSerializer()\n",
    "window_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a set of all unique sub-sequences with length = window_size from the training data\n",
    "\n",
    "The sequences from the training data are transposed over one octave.\n",
    "\n",
    "These sequences are then windowed to the previously decided number of events.\n",
    "\n",
    "Each window is converted to an equivalent string to make it a hashable object, and then added to a set for comparison with another set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data windows of length 100: 5208324\n",
      "Unique windows: 4423953\n"
     ]
    }
   ],
   "source": [
    "real_sequences = serializer.serialize_folder('./training_data/bach_chorales/')\n",
    "# transpose training data to all keys\n",
    "real_sequences = sequence_utils.transpose(real_sequences, down=-6, up=5)\n",
    "real_sequences, _ = sequence_utils.window(real_sequences, window_size=window_size)\n",
    "print('Training data windows of length {}: {}'.format(window_size, len(real_sequences)))\n",
    "\n",
    "real_set = set()\n",
    "for s in real_sequences:\n",
    "    s = '-'.join([str(x) for x in s])\n",
    "    real_set.add(s)\n",
    "print('Unique windows: {}'.format(len(real_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare generated sequences to the training data\n",
    "Sequences generated by the model using different seeds and temperature settings are serialized, converted to a hashable string, added to a set, and then compared to the training data one at a time.\n",
    "The percentage of unique windows in a generated composition that appear exactly in the training data is calculated.\n",
    "The average percentage of 'copied' sequences for an entire set of compositions using a given temperature setting is also calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPERATURE: 0.5\n",
      "sample_45-60-64-69.mid: 26.33% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_38-47-54-62-66.mid: 0.00% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_95.mid: 33.97% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_43-55-59-62-65.mid: 34.85% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_79.mid: 21.14% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_42.mid: 37.88% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "AVERAGE PERCENTAGE OVER ALL FILES: 25.69%\n",
      "********************************************************************************\n",
      "TEMPERATURE: 1.0\n",
      "sample_45-60-64-69.mid: 21.32% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_38-47-54-62-66.mid: 7.47% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_95.mid: 4.91% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_43-55-59-62-65.mid: 18.65% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_79.mid: 2.32% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_42.mid: 10.37% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "AVERAGE PERCENTAGE OVER ALL FILES: 10.84%\n",
      "********************************************************************************\n",
      "TEMPERATURE: 1.2\n",
      "sample_45-60-64-69.mid: 17.21% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_38-47-54-62-66.mid: 10.68% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_95.mid: 4.90% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_43-55-59-62-65.mid: 4.96% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_79.mid: 3.55% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_42.mid: 14.89% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "AVERAGE PERCENTAGE OVER ALL FILES: 9.37%\n",
      "********************************************************************************\n",
      "TEMPERATURE: 1.5\n",
      "sample_45-60-64-69.mid: 5.70% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_38-47-54-62-66.mid: 33.58% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_95.mid: 6.98% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_43-55-59-62-65.mid: 5.33% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_79.mid: 7.17% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_42.mid: 12.39% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "AVERAGE PERCENTAGE OVER ALL FILES: 11.86%\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "temperatures = [0.5, 1.0, 1.2, 1.5, 2.0, 3.0]\n",
    "\n",
    "for temp in temperatures:\n",
    "    print('TEMPERATURE: {}'.format(temp))\n",
    "    \n",
    "    percentages = []\n",
    "\n",
    "    # compare each generated sequence against the training set\n",
    "    for file in Path('./generated_files/bach_chorales_temperature_{}/'.format(temp)).glob('*.mid'):\n",
    "        \n",
    "        sequence = serializer.serialize(file)\n",
    "            \n",
    "        # split generated sequence into subsequences\n",
    "        gen_sequences, _ = sequence_utils.window([sequence], window_size=window_size)\n",
    "\n",
    "        # create a set of unique subsequences\n",
    "        gen_set = set()\n",
    "        for s in gen_sequences:\n",
    "            # turn subsequence into string so it is hashable\n",
    "            s = '-'.join([str(x) for x in s])\n",
    "            gen_set.add(s)\n",
    "\n",
    "        # find the intersection of the two sets to find all matching subsequences and calculate percentage of generated subsequences that come from the training data\n",
    "        matches = gen_set.intersection(real_set)\n",
    "        n_matches = len(matches)\n",
    "        total = len(gen_set)\n",
    "        percentage = n_matches/total * 100\n",
    "        percentages.append(percentage)\n",
    "\n",
    "        # print results\n",
    "        print('{}: {:.2f}% of unique windows (length = {}) from the generated composition exist in the training data.'.format(file.name, percentage, window_size))\n",
    "                        \n",
    "    average = sum(percentages) / len(percentages)\n",
    "    print('AVERAGE PERCENTAGE OVER ALL FILES: {:.2f}%'.format(average))\n",
    "    print('*' * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "This model is, for the most part, generating at least trivially unique sequences when sampled. The test does not take into account windows of events that might have just one or two events different.\n",
    "\n",
    "Using a higher temperature did make it more likely that generated sequences would be more unique, but there is still an element of randomness in the sampling at every temperature: for example, the lowest temperature (most predictable sampling) had one generated sequence with 0% of its windows copied from the training sequence while most other sequences had 21-38% of windows copied from the training data. Similarly, the highest temperature setting had a single generated sequence that had a relatively high percentage of windows copied from the training data, at 33.58%, while the other sequences all had percentages between 5.5-12.5%\n",
    "\n",
    "Through listening tests, it seemed that lower temperatures had a more clear musical structure, but each generated composition is unique. Sampling from the model could be another area to explore for optimal settings, by choosing the seed and temperature settings and generating multiple options using the same settings.\n",
    "\n",
    "This experiment raises questions that I do not currently have a clear answer to, and might be beyond the scope of this project, like what makes a composition unique, and what level of similarity is acceptable for a composition to be considered new? What would be the level of copied sequences found using a human composer who studied the training set and then tried to create a new composition in the same style?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
