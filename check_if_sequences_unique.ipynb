{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_generator.serializers.discrete_time_serializer import DiscreteTimeMidiSerializer\n",
    "import music_generator.utilities.sequence_utils as sequence_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real sequence windows of length 100: 648120\n",
      "Unique windows: 619019\n"
     ]
    }
   ],
   "source": [
    "serializer = DiscreteTimeMidiSerializer()\n",
    "\n",
    "window_size = 100\n",
    "\n",
    "real_sequences = serializer.serialize_folder('./training_data/chopin_nocturnes/')\n",
    "real_sequences = sequence_utils.transpose(real_sequences, down=-2, up=2)\n",
    "real_sequences, _ = sequence_utils.window(real_sequences, window_size=window_size)\n",
    "print('Real sequence windows of length {}: {}'.format(window_size, len(real_sequences)))\n",
    "\n",
    "real_set = set()\n",
    "for s in real_sequences:\n",
    "    s = '-'.join([str(x) for x in s])\n",
    "    real_set.add(s)\n",
    "print('Unique windows: {}'.format(len(real_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence windows of length 100: 898\n",
      "Unique windows: 885\n"
     ]
    }
   ],
   "source": [
    "gen_sequences = serializer.serialize('./generated_files/chopin_nocturnes_transposed/sample_43-55-59-62-65.mid')\n",
    "gen_sequences, _ = sequence_utils.window([gen_sequences], window_size=window_size)\n",
    "print('Generated sequence windows of length {}: {}'.format(window_size, len(gen_sequences)))\n",
    "\n",
    "gen_set = set()\n",
    "for s in gen_sequences:\n",
    "    s = '-'.join([str(x) for x in s])\n",
    "    gen_set.add(s)\n",
    "print('Unique windows: {}'.format(len(gen_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467 -- 52.76836158192091% of unique windows (length = 100) from the generated composition exist in the training data.\n"
     ]
    }
   ],
   "source": [
    "union = gen_set.intersection(real_set)\n",
    "matches = len(union)\n",
    "total = len(gen_set)\n",
    "percentage = matches/total * 100\n",
    "print('{} -- {}% of unique windows (length = {}) from the generated composition exist in the training data.'.format(matches, percentage, window_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "Total running time of 6 generated 1000-event files is: 4 minutes 2 seconds = 242 seconds.\n",
    "\n",
    "6000 events / 242 seconds ~ 25 events per seconds.\n",
    "\n",
    "100 events is, on average, approximately 4 seconds of music.\n",
    "\n",
    "Where is the line between copying and generating in a style? At what sequence length is it copying?\n",
    "\n",
    "- A single 4-note chord being pressed and held for a period of time and then released would be 9 events minimum.\n",
    "- A measure of 4 chords with 4 voices playing quarter notes would be 36 events minimum.\n",
    "\n",
    "If a human composer were trying to generate a composition in this compositional style, what percentage of copying 10 second sequences would they generate by accident?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
