{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README: How to train a model on a dataset of Bach Chorales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0-dev20200327\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from music_generator.model import MusicModel\n",
    "from music_generator.serializers.discrete_time_serializer import DiscreteTimeMidiSerializer\n",
    "import music_generator.utilities.sequence_utils as sequence_utils\n",
    "import music_generator.utilities.utils as utils\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if CUDA and GPU are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA and GPU Available.\n"
     ]
    }
   ],
   "source": [
    "for message in utils.check_cuda_and_gpu():\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model\n",
    "\n",
    "The default model architecture and hyperparameters are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"music_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         45568     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 512)         1312768   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 512)         2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 356)               182628    \n",
      "=================================================================\n",
      "Total params: 6,010,212\n",
      "Trainable params: 6,006,116\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "description = 'bach_chorales'\n",
    "\n",
    "model = MusicModel(\n",
    "    ckpt_dir='./training_checkpoints/{}'.format(description),\n",
    "    log_dir='./logs/{}'.format(description))\n",
    "\n",
    "model.compile()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "\n",
    "A folder of MIDI files are serialized into event sequences.\n",
    "\n",
    "The sequences are windowed and the last event split off to use as a label for the model to train on - predicting the next event from the given sequence.\n",
    "\n",
    "A training and validation dataset are created from the sequences and labels - the validation dataset is used in a callback to reduce the learning rate when validation loss plateaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sequences: 412325\n",
      "Validation Sequences: 21702\n"
     ]
    }
   ],
   "source": [
    "data_path = './training_data/bach_chorales/'\n",
    "\n",
    "serializer = DiscreteTimeMidiSerializer()\n",
    "\n",
    "sequences = serializer.serialize_folder(data_path)\n",
    "sequences, labels = sequence_utils.window(sequences)\n",
    "\n",
    "dataset_train, dataset_val = sequence_utils.make_tf_datasets(sequences, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model on Dataset\n",
    "\n",
    "Progress can also be monitored via TensorBoard.\n",
    "\n",
    "The learning rate of the optimizer will be reduced when validation loss stalls.\n",
    "\n",
    "The checkpoint with the best training loss will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3221/3221 [==============================] - 480s 149ms/step - loss: 1.1480 - sparse_categorical_accuracy: 0.6765 - val_loss: 0.8154 - val_sparse_categorical_accuracy: 0.7439 - lr: 3.0000e-04\n",
      "Epoch 2/100\n",
      "3221/3221 [==============================] - 496s 154ms/step - loss: 0.6871 - sparse_categorical_accuracy: 0.7795 - val_loss: 0.6062 - val_sparse_categorical_accuracy: 0.8027 - lr: 3.0000e-04\n",
      "Epoch 3/100\n",
      "3221/3221 [==============================] - 497s 154ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.8134 - val_loss: 0.5539 - val_sparse_categorical_accuracy: 0.8192 - lr: 3.0000e-04\n",
      "Epoch 4/100\n",
      "3221/3221 [==============================] - 498s 155ms/step - loss: 0.4848 - sparse_categorical_accuracy: 0.8363 - val_loss: 0.5052 - val_sparse_categorical_accuracy: 0.8353 - lr: 3.0000e-04\n",
      "Epoch 5/100\n",
      "3221/3221 [==============================] - 501s 156ms/step - loss: 0.4232 - sparse_categorical_accuracy: 0.8553 - val_loss: 0.4885 - val_sparse_categorical_accuracy: 0.8437 - lr: 3.0000e-04\n",
      "Epoch 6/100\n",
      "3221/3221 [==============================] - 501s 155ms/step - loss: 0.3699 - sparse_categorical_accuracy: 0.8715 - val_loss: 0.4844 - val_sparse_categorical_accuracy: 0.8451 - lr: 3.0000e-04\n",
      "Epoch 7/100\n",
      "3221/3221 [==============================] - 498s 155ms/step - loss: 0.3262 - sparse_categorical_accuracy: 0.8859 - val_loss: 0.4819 - val_sparse_categorical_accuracy: 0.8493 - lr: 3.0000e-04\n",
      "Epoch 8/100\n",
      "3221/3221 [==============================] - 497s 154ms/step - loss: 0.2883 - sparse_categorical_accuracy: 0.8985 - val_loss: 0.4840 - val_sparse_categorical_accuracy: 0.8511 - lr: 3.0000e-04\n",
      "Epoch 9/100\n",
      "3221/3221 [==============================] - ETA: 0s - loss: 0.2569 - sparse_categorical_accuracy: 0.9090\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "3221/3221 [==============================] - 493s 153ms/step - loss: 0.2569 - sparse_categorical_accuracy: 0.9090 - val_loss: 0.4994 - val_sparse_categorical_accuracy: 0.8555 - lr: 3.0000e-04\n",
      "Epoch 10/100\n",
      "3221/3221 [==============================] - 495s 154ms/step - loss: 0.1765 - sparse_categorical_accuracy: 0.9376 - val_loss: 0.4635 - val_sparse_categorical_accuracy: 0.8719 - lr: 9.0000e-05\n",
      "Epoch 11/100\n",
      "3221/3221 [==============================] - 494s 153ms/step - loss: 0.1374 - sparse_categorical_accuracy: 0.9519 - val_loss: 0.4783 - val_sparse_categorical_accuracy: 0.8735 - lr: 9.0000e-05\n",
      "Epoch 12/100\n",
      "3221/3221 [==============================] - 495s 154ms/step - loss: 0.1172 - sparse_categorical_accuracy: 0.9592 - val_loss: 0.4925 - val_sparse_categorical_accuracy: 0.8755 - lr: 9.0000e-05\n",
      "Epoch 13/100\n",
      "3221/3221 [==============================] - 494s 153ms/step - loss: 0.1022 - sparse_categorical_accuracy: 0.9643 - val_loss: 0.5072 - val_sparse_categorical_accuracy: 0.8782 - lr: 9.0000e-05\n",
      "Epoch 14/100\n",
      "3221/3221 [==============================] - 496s 154ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9684 - val_loss: 0.5287 - val_sparse_categorical_accuracy: 0.8780 - lr: 9.0000e-05\n",
      "Epoch 15/100\n",
      "3221/3221 [==============================] - ETA: 0s - loss: 0.0818 - sparse_categorical_accuracy: 0.9714\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "3221/3221 [==============================] - 495s 154ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.5455 - val_sparse_categorical_accuracy: 0.8781 - lr: 9.0000e-05\n",
      "Epoch 16/100\n",
      "3221/3221 [==============================] - 496s 154ms/step - loss: 0.0657 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.5413 - val_sparse_categorical_accuracy: 0.8814 - lr: 2.7000e-05\n",
      "Epoch 17/100\n",
      "3221/3221 [==============================] - 496s 154ms/step - loss: 0.0558 - sparse_categorical_accuracy: 0.9815 - val_loss: 0.5493 - val_sparse_categorical_accuracy: 0.8820 - lr: 2.7000e-05\n",
      "Epoch 18/100\n",
      "3221/3221 [==============================] - 503s 156ms/step - loss: 0.0514 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.5562 - val_sparse_categorical_accuracy: 0.8817 - lr: 2.7000e-05\n",
      "Epoch 19/100\n",
      "3221/3221 [==============================] - 497s 154ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9845 - val_loss: 0.5627 - val_sparse_categorical_accuracy: 0.8817 - lr: 2.7000e-05\n",
      "Epoch 20/100\n",
      "3221/3221 [==============================] - 494s 154ms/step - loss: 0.0451 - sparse_categorical_accuracy: 0.9855 - val_loss: 0.5723 - val_sparse_categorical_accuracy: 0.8820 - lr: 2.7000e-05\n",
      "Epoch 21/100\n",
      "3221/3221 [==============================] - ETA: 0s - loss: 0.0423 - sparse_categorical_accuracy: 0.9866\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "3221/3221 [==============================] - 496s 154ms/step - loss: 0.0423 - sparse_categorical_accuracy: 0.9866 - val_loss: 0.5808 - val_sparse_categorical_accuracy: 0.8830 - lr: 2.7000e-05\n",
      "Epoch 22/100\n",
      "3221/3221 [==============================] - 495s 154ms/step - loss: 0.0389 - sparse_categorical_accuracy: 0.9878 - val_loss: 0.5836 - val_sparse_categorical_accuracy: 0.8824 - lr: 8.1000e-06\n",
      "Epoch 23/100\n",
      "3221/3221 [==============================] - 495s 154ms/step - loss: 0.0366 - sparse_categorical_accuracy: 0.9887 - val_loss: 0.5876 - val_sparse_categorical_accuracy: 0.8827 - lr: 8.1000e-06\n",
      "Epoch 24/100\n",
      "3221/3221 [==============================] - 494s 153ms/step - loss: 0.0350 - sparse_categorical_accuracy: 0.9891 - val_loss: 0.5906 - val_sparse_categorical_accuracy: 0.8823 - lr: 8.1000e-06\n",
      "Epoch 25/100\n",
      "3221/3221 [==============================] - 496s 154ms/step - loss: 0.0342 - sparse_categorical_accuracy: 0.9896 - val_loss: 0.5927 - val_sparse_categorical_accuracy: 0.8838 - lr: 8.1000e-06\n",
      "Epoch 26/100\n",
      "3221/3221 [==============================] - 497s 154ms/step - loss: 0.0331 - sparse_categorical_accuracy: 0.9899 - val_loss: 0.5950 - val_sparse_categorical_accuracy: 0.8835 - lr: 8.1000e-06\n",
      "Epoch 27/100\n",
      "3221/3221 [==============================] - ETA: 0s - loss: 0.0321 - sparse_categorical_accuracy: 0.9905\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "3221/3221 [==============================] - 495s 154ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.5987 - val_sparse_categorical_accuracy: 0.8839 - lr: 8.1000e-06\n",
      "Epoch 28/100\n",
      "3221/3221 [==============================] - 493s 153ms/step - loss: 0.0313 - sparse_categorical_accuracy: 0.9905 - val_loss: 0.5990 - val_sparse_categorical_accuracy: 0.8835 - lr: 2.4300e-06\n",
      "Epoch 29/100\n",
      "3221/3221 [==============================] - 493s 153ms/step - loss: 0.0308 - sparse_categorical_accuracy: 0.9906 - val_loss: 0.6003 - val_sparse_categorical_accuracy: 0.8835 - lr: 2.4300e-06\n",
      "Epoch 30/100\n",
      "3221/3221 [==============================] - 494s 153ms/step - loss: 0.0304 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.6014 - val_sparse_categorical_accuracy: 0.8833 - lr: 2.4300e-06\n",
      "Epoch 31/100\n",
      "3221/3221 [==============================] - 494s 153ms/step - loss: 0.0300 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.6022 - val_sparse_categorical_accuracy: 0.8837 - lr: 2.4300e-06\n",
      "Epoch 32/100\n",
      "3221/3221 [==============================] - 494s 153ms/step - loss: 0.0298 - sparse_categorical_accuracy: 0.9912 - val_loss: 0.6036 - val_sparse_categorical_accuracy: 0.8839 - lr: 2.4300e-06\n",
      "Epoch 33/100\n",
      " 382/3221 [==>...........................] - ETA: 7:02 - loss: 0.0322 - sparse_categorical_accuracy: 0.9903\n",
      "Stopping training...\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "try:\n",
    "    history = model.fit(dataset_train,\n",
    "                    validation_data=dataset_val,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)\n",
    "except KeyboardInterrupt as e:\n",
    "    print('\\nStopping training...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
