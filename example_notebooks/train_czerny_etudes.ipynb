{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README: How to train a model on a dataset of Czerny Etudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0-dev20200327\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from music_generator.model import MusicModel\n",
    "from music_generator.serializers.discrete_time_serializer import DiscreteTimeMidiSerializer\n",
    "import music_generator.utilities.sequence_utils as sequence_utils\n",
    "import music_generator.utilities.utils as utils\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if CUDA and GPU are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA and GPU Available.\n"
     ]
    }
   ],
   "source": [
    "for message in utils.check_cuda_and_gpu():\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model\n",
    "\n",
    "The default model architecture and hyperparameters are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"music_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         45568     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 512)         1312768   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 512)         2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 356)               182628    \n",
      "=================================================================\n",
      "Total params: 6,010,212\n",
      "Trainable params: 6,006,116\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "description = 'czerny_etudes'\n",
    "\n",
    "model = MusicModel(\n",
    "    ckpt_dir='./training_checkpoints/{}'.format(description),\n",
    "    log_dir='./logs/{}'.format(description))\n",
    "\n",
    "model.compile()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "\n",
    "A folder of MIDI files are serialized into event sequences.\n",
    "\n",
    "All sequences are then transposed over a range from 1 whole-step down, to 1.5 whole-steps up. This effectively multiplies the number of sequences by five, and similarly increases training time per epoch by about a factor of six. The result is reduced overfitting and better generated sequences. Whether the benefit outweighs the additional training time will depend on the training data and compositional style.\n",
    "\n",
    "Finally, the sequences are windowed and the last event split off to use as a label for the model to train on - predicting the next event from the given sequence.\n",
    "\n",
    "A training and validation dataset are created from the sequences and labels - the validation dataset is used in a callback to reduce the learning rate when validation loss plateaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sequences: 677621\n",
      "Validation Sequences: 35665\n"
     ]
    }
   ],
   "source": [
    "data_path = './training_data/czerny_etudes/'\n",
    "\n",
    "serializer = DiscreteTimeMidiSerializer()\n",
    "\n",
    "sequences = serializer.serialize_folder(data_path)\n",
    "sequences = sequence_utils.transpose(sequences, down=-2, up=3)\n",
    "sequences, labels = sequence_utils.window(sequences)\n",
    "\n",
    "dataset_train, dataset_val = sequence_utils.make_tf_datasets(sequences, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model on Dataset\n",
    "\n",
    "Progress can also be monitored via TensorBoard.\n",
    "\n",
    "The learning rate of the optimizer will be reduced when validation loss stalls.\n",
    "\n",
    "The checkpoint with the best training loss will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5293/5293 [==============================] - 804s 152ms/step - loss: 1.9984 - sparse_categorical_accuracy: 0.5424 - val_loss: 1.0716 - val_sparse_categorical_accuracy: 0.7048 - lr: 3.0000e-04\n",
      "Epoch 2/100\n",
      "5293/5293 [==============================] - 816s 154ms/step - loss: 0.9519 - sparse_categorical_accuracy: 0.7301 - val_loss: 0.7542 - val_sparse_categorical_accuracy: 0.7797 - lr: 3.0000e-04\n",
      "Epoch 3/100\n",
      "5293/5293 [==============================] - 823s 156ms/step - loss: 0.7016 - sparse_categorical_accuracy: 0.7922 - val_loss: 0.6066 - val_sparse_categorical_accuracy: 0.8176 - lr: 3.0000e-04\n",
      "Epoch 4/100\n",
      "5293/5293 [==============================] - 818s 155ms/step - loss: 0.5581 - sparse_categorical_accuracy: 0.8294 - val_loss: 0.5196 - val_sparse_categorical_accuracy: 0.8428 - lr: 3.0000e-04\n",
      "Epoch 5/100\n",
      "5293/5293 [==============================] - 820s 155ms/step - loss: 0.4628 - sparse_categorical_accuracy: 0.8556 - val_loss: 0.4685 - val_sparse_categorical_accuracy: 0.8574 - lr: 3.0000e-04\n",
      "Epoch 6/100\n",
      "5293/5293 [==============================] - 819s 155ms/step - loss: 0.3938 - sparse_categorical_accuracy: 0.8751 - val_loss: 0.4349 - val_sparse_categorical_accuracy: 0.8692 - lr: 3.0000e-04\n",
      "Epoch 7/100\n",
      "5293/5293 [==============================] - 822s 155ms/step - loss: 0.3409 - sparse_categorical_accuracy: 0.8910 - val_loss: 0.4013 - val_sparse_categorical_accuracy: 0.8784 - lr: 3.0000e-04\n",
      "Epoch 8/100\n",
      "5293/5293 [==============================] - 827s 156ms/step - loss: 0.2988 - sparse_categorical_accuracy: 0.9033 - val_loss: 0.3709 - val_sparse_categorical_accuracy: 0.8879 - lr: 3.0000e-04\n",
      "Epoch 9/100\n",
      "5293/5293 [==============================] - 825s 156ms/step - loss: 0.2655 - sparse_categorical_accuracy: 0.9134 - val_loss: 0.3564 - val_sparse_categorical_accuracy: 0.8936 - lr: 3.0000e-04\n",
      "Epoch 10/100\n",
      "5293/5293 [==============================] - 821s 155ms/step - loss: 0.2382 - sparse_categorical_accuracy: 0.9218 - val_loss: 0.3444 - val_sparse_categorical_accuracy: 0.8982 - lr: 3.0000e-04\n",
      "Epoch 11/100\n",
      "5293/5293 [==============================] - 816s 154ms/step - loss: 0.2169 - sparse_categorical_accuracy: 0.9285 - val_loss: 0.3280 - val_sparse_categorical_accuracy: 0.9044 - lr: 3.0000e-04\n",
      "Epoch 12/100\n",
      "5293/5293 [==============================] - 813s 154ms/step - loss: 0.1983 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.3135 - val_sparse_categorical_accuracy: 0.9081 - lr: 3.0000e-04\n",
      "Epoch 13/100\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.1822 - sparse_categorical_accuracy: 0.9396 - val_loss: 0.3096 - val_sparse_categorical_accuracy: 0.9113 - lr: 3.0000e-04\n",
      "Epoch 14/100\n",
      "5293/5293 [==============================] - 813s 154ms/step - loss: 0.1693 - sparse_categorical_accuracy: 0.9438 - val_loss: 0.3053 - val_sparse_categorical_accuracy: 0.9135 - lr: 3.0000e-04\n",
      "Epoch 15/100\n",
      "5293/5293 [==============================] - 814s 154ms/step - loss: 0.1579 - sparse_categorical_accuracy: 0.9475 - val_loss: 0.3055 - val_sparse_categorical_accuracy: 0.9155 - lr: 3.0000e-04\n",
      "Epoch 16/100\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.1465 - sparse_categorical_accuracy: 0.9511 - val_loss: 0.2973 - val_sparse_categorical_accuracy: 0.9203 - lr: 3.0000e-04\n",
      "Epoch 17/100\n",
      "5293/5293 [==============================] - 816s 154ms/step - loss: 0.1389 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.2875 - val_sparse_categorical_accuracy: 0.9211 - lr: 3.0000e-04\n",
      "Epoch 18/100\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.1298 - sparse_categorical_accuracy: 0.9562 - val_loss: 0.2918 - val_sparse_categorical_accuracy: 0.9211 - lr: 3.0000e-04\n",
      "Epoch 19/100\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.1229 - sparse_categorical_accuracy: 0.9586 - val_loss: 0.2829 - val_sparse_categorical_accuracy: 0.9242 - lr: 3.0000e-04\n",
      "Epoch 20/100\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.1169 - sparse_categorical_accuracy: 0.9608 - val_loss: 0.2808 - val_sparse_categorical_accuracy: 0.9260 - lr: 3.0000e-04\n",
      "Epoch 21/100\n",
      "5293/5293 [==============================] - 809s 153ms/step - loss: 0.1121 - sparse_categorical_accuracy: 0.9625 - val_loss: 0.2749 - val_sparse_categorical_accuracy: 0.9290 - lr: 3.0000e-04\n",
      "Epoch 22/100\n",
      "5293/5293 [==============================] - 813s 154ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9644 - val_loss: 0.2748 - val_sparse_categorical_accuracy: 0.9291 - lr: 3.0000e-04\n",
      "Epoch 23/100\n",
      "5293/5293 [==============================] - 813s 154ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9656 - val_loss: 0.2705 - val_sparse_categorical_accuracy: 0.9294 - lr: 3.0000e-04\n",
      "Epoch 24/100\n",
      "5293/5293 [==============================] - 814s 154ms/step - loss: 0.0976 - sparse_categorical_accuracy: 0.9671 - val_loss: 0.2630 - val_sparse_categorical_accuracy: 0.9321 - lr: 3.0000e-04\n",
      "Epoch 25/100\n",
      "5293/5293 [==============================] - 816s 154ms/step - loss: 0.0941 - sparse_categorical_accuracy: 0.9685 - val_loss: 0.2679 - val_sparse_categorical_accuracy: 0.9327 - lr: 3.0000e-04\n",
      "Epoch 26/100\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.0908 - sparse_categorical_accuracy: 0.9694 - val_loss: 0.2567 - val_sparse_categorical_accuracy: 0.9360 - lr: 3.0000e-04\n",
      "Epoch 27/100\n",
      "5293/5293 [==============================] - 814s 154ms/step - loss: 0.0863 - sparse_categorical_accuracy: 0.9711 - val_loss: 0.2575 - val_sparse_categorical_accuracy: 0.9352 - lr: 3.0000e-04\n",
      "Epoch 28/100\n",
      "5293/5293 [==============================] - ETA: 0s - loss: 0.0844 - sparse_categorical_accuracy: 0.9718\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "5293/5293 [==============================] - 813s 154ms/step - loss: 0.0844 - sparse_categorical_accuracy: 0.9718 - val_loss: 0.2606 - val_sparse_categorical_accuracy: 0.9340 - lr: 3.0000e-04\n",
      "Epoch 29/100\n",
      "5293/5293 [==============================] - 814s 154ms/step - loss: 0.0517 - sparse_categorical_accuracy: 0.9827 - val_loss: 0.2251 - val_sparse_categorical_accuracy: 0.9453 - lr: 9.0000e-05\n",
      "Epoch 30/100\n",
      "5293/5293 [==============================] - 816s 154ms/step - loss: 0.0368 - sparse_categorical_accuracy: 0.9877 - val_loss: 0.2273 - val_sparse_categorical_accuracy: 0.9457 - lr: 9.0000e-05\n",
      "Epoch 31/100\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.0322 - sparse_categorical_accuracy: 0.9892 - val_loss: 0.2292 - val_sparse_categorical_accuracy: 0.9464 - lr: 9.0000e-05\n",
      "Epoch 32/100\n",
      "5293/5293 [==============================] - 816s 154ms/step - loss: 0.0289 - sparse_categorical_accuracy: 0.9904 - val_loss: 0.2297 - val_sparse_categorical_accuracy: 0.9481 - lr: 9.0000e-05\n",
      "Epoch 33/100\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9911 - val_loss: 0.2324 - val_sparse_categorical_accuracy: 0.9476 - lr: 9.0000e-05\n",
      "Epoch 34/100\n",
      "5293/5293 [==============================] - ETA: 0s - loss: 0.0256 - sparse_categorical_accuracy: 0.9915\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.0256 - sparse_categorical_accuracy: 0.9915 - val_loss: 0.2352 - val_sparse_categorical_accuracy: 0.9487 - lr: 9.0000e-05\n",
      "Epoch 35/100\n",
      "5293/5293 [==============================] - 816s 154ms/step - loss: 0.0207 - sparse_categorical_accuracy: 0.9932 - val_loss: 0.2296 - val_sparse_categorical_accuracy: 0.9501 - lr: 2.7000e-05\n",
      "Epoch 36/100\n",
      "5293/5293 [==============================] - 815s 154ms/step - loss: 0.0176 - sparse_categorical_accuracy: 0.9943 - val_loss: 0.2286 - val_sparse_categorical_accuracy: 0.9504 - lr: 2.7000e-05\n",
      "Epoch 37/100\n",
      "5293/5293 [==============================] - 859s 162ms/step - loss: 0.0161 - sparse_categorical_accuracy: 0.9947 - val_loss: 0.2296 - val_sparse_categorical_accuracy: 0.9503 - lr: 2.7000e-05\n",
      "Epoch 38/100\n",
      "5293/5293 [==============================] - 876s 165ms/step - loss: 0.0150 - sparse_categorical_accuracy: 0.9951 - val_loss: 0.2305 - val_sparse_categorical_accuracy: 0.9507 - lr: 2.7000e-05\n",
      "Epoch 39/100\n",
      "5293/5293 [==============================] - 859s 162ms/step - loss: 0.0145 - sparse_categorical_accuracy: 0.9952 - val_loss: 0.2323 - val_sparse_categorical_accuracy: 0.9510 - lr: 2.7000e-05\n",
      "Epoch 40/100\n",
      "5293/5293 [==============================] - ETA: 0s - loss: 0.0137 - sparse_categorical_accuracy: 0.9956\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "5293/5293 [==============================] - 884s 167ms/step - loss: 0.0137 - sparse_categorical_accuracy: 0.9956 - val_loss: 0.2343 - val_sparse_categorical_accuracy: 0.9509 - lr: 2.7000e-05\n",
      "Epoch 41/100\n",
      "5293/5293 [==============================] - 873s 165ms/step - loss: 0.0125 - sparse_categorical_accuracy: 0.9960 - val_loss: 0.2337 - val_sparse_categorical_accuracy: 0.9512 - lr: 8.1000e-06\n",
      "Epoch 42/100\n",
      "5293/5293 [==============================] - 901s 170ms/step - loss: 0.0119 - sparse_categorical_accuracy: 0.9962 - val_loss: 0.2333 - val_sparse_categorical_accuracy: 0.9512 - lr: 8.1000e-06\n",
      "Epoch 43/100\n",
      "5293/5293 [==============================] - 837s 158ms/step - loss: 0.0121 - sparse_categorical_accuracy: 0.9961 - val_loss: 0.2334 - val_sparse_categorical_accuracy: 0.9514 - lr: 8.1000e-06\n",
      "Epoch 44/100\n",
      "5293/5293 [==============================] - 822s 155ms/step - loss: 0.0111 - sparse_categorical_accuracy: 0.9964 - val_loss: 0.2333 - val_sparse_categorical_accuracy: 0.9518 - lr: 8.1000e-06\n",
      "Epoch 45/100\n",
      "5293/5293 [==============================] - 822s 155ms/step - loss: 0.0112 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.2337 - val_sparse_categorical_accuracy: 0.9513 - lr: 8.1000e-06\n",
      "Epoch 46/100\n",
      "5293/5293 [==============================] - ETA: 0s - loss: 0.0110 - sparse_categorical_accuracy: 0.9965\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "5293/5293 [==============================] - 822s 155ms/step - loss: 0.0110 - sparse_categorical_accuracy: 0.9965 - val_loss: 0.2337 - val_sparse_categorical_accuracy: 0.9516 - lr: 8.1000e-06\n",
      "Epoch 47/100\n",
      "5293/5293 [==============================] - 823s 156ms/step - loss: 0.0108 - sparse_categorical_accuracy: 0.9966 - val_loss: 0.2339 - val_sparse_categorical_accuracy: 0.9518 - lr: 2.4300e-06\n",
      "Epoch 48/100\n",
      "5293/5293 [==============================] - 823s 155ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.2340 - val_sparse_categorical_accuracy: 0.9515 - lr: 2.4300e-06\n",
      "Epoch 49/100\n",
      "5293/5293 [==============================] - 822s 155ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.2339 - val_sparse_categorical_accuracy: 0.9515 - lr: 2.4300e-06\n",
      "Epoch 50/100\n",
      "5293/5293 [==============================] - 822s 155ms/step - loss: 0.0103 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.2341 - val_sparse_categorical_accuracy: 0.9515 - lr: 2.4300e-06\n",
      "Epoch 51/100\n",
      "5293/5293 [==============================] - 823s 155ms/step - loss: 0.0101 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.2340 - val_sparse_categorical_accuracy: 0.9516 - lr: 2.4300e-06\n",
      "Epoch 52/100\n",
      "5293/5293 [==============================] - ETA: 0s - loss: 0.0102 - sparse_categorical_accuracy: 0.9968\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "5293/5293 [==============================] - 824s 156ms/step - loss: 0.0102 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.2342 - val_sparse_categorical_accuracy: 0.9518 - lr: 2.4300e-06\n",
      "Epoch 53/100\n",
      "5293/5293 [==============================] - 824s 156ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9968 - val_loss: 0.2343 - val_sparse_categorical_accuracy: 0.9517 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "5293/5293 [==============================] - 824s 156ms/step - loss: 0.0104 - sparse_categorical_accuracy: 0.9967 - val_loss: 0.2342 - val_sparse_categorical_accuracy: 0.9517 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "5293/5293 [==============================] - 822s 155ms/step - loss: 0.0100 - sparse_categorical_accuracy: 0.9969 - val_loss: 0.2340 - val_sparse_categorical_accuracy: 0.9518 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "3866/5293 [====================>.........] - ETA: 3:37 - loss: 0.0104 - sparse_categorical_accuracy: 0.9967"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "try:\n",
    "    history = model.fit(dataset_train,\n",
    "                    validation_data=dataset_val,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)\n",
    "except KeyboardInterrupt as e:\n",
    "    print('\\nStopping training...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
