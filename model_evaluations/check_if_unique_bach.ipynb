{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bach Chorales - analysing matching subsequences in training and generated data\n",
    "## Comparing Generated Sequences to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music_generator.serializers.discrete_time_serializer import DiscreteTimeMidiSerializer\n",
    "import music_generator.utilities.sequence_utils as sequence_utils\n",
    "import music_generator.utilities.utils as utils\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up constants for generation and comparison\n",
    "\n",
    "A single quarter-note four-voice chord would be made up of at least 9 events (4 note-on, 4 note-off, at least 4 wait events if no chaining is required),\n",
    "so a measure of four quarter-note four-voice chords would be a minimum of 36 events.\n",
    "\n",
    "Adding in eigth notes, flourishes, etc. would increase the number of events in a measure.\n",
    "\n",
    "Windows of 100 events are used to compare generated sequences and training sequences. This would generally represent somewhere from one to four measures, depending on note frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "serializer = DiscreteTimeMidiSerializer()\n",
    "window_size = 100\n",
    "training_data = './training_data/bach_chorales/'\n",
    "generated_data = './generated_files/bach_chorales_temperature_{}/'\n",
    "temperatures = [1.0, 1.2, 1.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a set of all unique sub-sequences with length = window_size from the training data\n",
    "\n",
    "The sequences from the training data are transposed over one octave.\n",
    "\n",
    "These sequences are then windowed to the previously decided number of events.\n",
    "\n",
    "Each window is converted to an equivalent string to make it a hashable object, and then added to a set for comparison with another set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data windows of length 100: 5208324\n",
      "Unique windows: 4423953\n"
     ]
    }
   ],
   "source": [
    "real_sequences = serializer.serialize_folder(training_data)\n",
    "\n",
    "# transpose training data to all keys and window\n",
    "real_sequences = sequence_utils.transpose(real_sequences, down=-6, up=5)\n",
    "real_sequences, _ = sequence_utils.window(real_sequences, window_size=window_size)\n",
    "print('Training data windows of length {}: {}'.format(window_size, len(real_sequences)))\n",
    "\n",
    "real_set = utils.create_hashable_set(real_sequences)\n",
    "print('Unique windows: {}'.format(len(real_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare generated sequences to the training data\n",
    "Sequences generated by the model using different seeds and temperature settings are serialized, converted to a hashable string, added to a set, and then compared to the training data one at a time.\n",
    "The percentage of unique windows in a generated composition that appear exactly in the training data is calculated.\n",
    "The average percentage of 'copied' sequences for an entire set of compositions using a given temperature setting is also calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEMPERATURE: 1.0\n",
      "sample_45-60-64-69.mid: 7.79% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_38-47-54-62-66.mid: 50.93% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_41-50-57-65-69.mid: 35.61% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_39-48-55-63-67.mid: 47.28% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_40-49-56-64-68.mid: 18.79% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_43-55-59-62-65.mid: 29.91% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "AVERAGE PERCENTAGE OVER ALL FILES: 31.72%\n",
      "********************************************************************************\n",
      "TEMPERATURE: 1.2\n",
      "sample_45-60-64-69.mid: 8.32% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_38-47-54-62-66.mid: 1.37% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_41-50-57-65-69.mid: 23.68% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_39-48-55-63-67.mid: 0.00% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_40-49-56-64-68.mid: 3.74% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_43-55-59-62-65.mid: 4.53% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "AVERAGE PERCENTAGE OVER ALL FILES: 6.94%\n",
      "********************************************************************************\n",
      "TEMPERATURE: 1.5\n",
      "sample_45-60-64-69.mid: 8.00% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_38-47-54-62-66.mid: 0.37% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_41-50-57-65-69.mid: 28.73% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_39-48-55-63-67.mid: 0.00% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_40-49-56-64-68.mid: 5.11% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "sample_43-55-59-62-65.mid: 3.80% of unique windows (length = 100) from the generated composition exist in the training data.\n",
      "AVERAGE PERCENTAGE OVER ALL FILES: 7.67%\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for temp in temperatures:\n",
    "    print('TEMPERATURE: {}'.format(temp))\n",
    "    \n",
    "    percentages = []\n",
    "\n",
    "    # compare each generated sequence against the training set\n",
    "    for file in Path(generated_data.format(temp)).glob('*.mid'):\n",
    "        \n",
    "        sequence = serializer.serialize(file)\n",
    "            \n",
    "        # split generated sequence into subsequences\n",
    "        gen_sequences, _ = sequence_utils.window([sequence], window_size=window_size)\n",
    "\n",
    "        # create a set of unique subsequences\n",
    "        gen_set = utils.create_hashable_set(gen_sequences)\n",
    "\n",
    "        # find the intersection of the two sets to find all matching subsequences and calculate percentage of generated subsequences that come from the training data\n",
    "        matches = gen_set.intersection(real_set)\n",
    "        n_matches = len(matches)\n",
    "        total = len(gen_set)\n",
    "        percentage = n_matches/total * 100\n",
    "        percentages.append(percentage)\n",
    "\n",
    "        # print results\n",
    "        print('{}: {:.2f}% of unique windows (length = {}) from the generated composition exist in the training data.'.format(file.name, percentage, window_size))\n",
    "                        \n",
    "    average = sum(percentages) / len(percentages)\n",
    "    print('AVERAGE PERCENTAGE OVER ALL FILES: {:.2f}%'.format(average))\n",
    "    print('*' * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often does Bach repeat himself?\n",
    "\n",
    "Each composition of the dataset is checked against the rest of the dataset and its transpositions, as above, to find how much repetition appears across compositions in the dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "040900B_.mid: 56.63% of unique windows from the composition exist in the other training data compositions.\n",
      "010406B_.mid: 3.34% of unique windows from the composition exist in the other training data compositions.\n",
      "001805Bw.mid: 88.85% of unique windows from the composition exist in the other training data compositions.\n",
      "040900Bv.mid: 58.02% of unique windows from the composition exist in the other training data compositions.\n",
      "024835B3.mid: 59.21% of unique windows from the composition exist in the other training data compositions.\n",
      "024805B_.mid: 1.27% of unique windows from the composition exist in the other training data compositions.\n",
      "024417B_.mid: 100.00% of unique windows from the composition exist in the other training data compositions.\n",
      "001007B_.mid: 8.35% of unique windows from the composition exist in the other training data compositions.\n",
      "024511B_.mid: 17.93% of unique windows from the composition exist in the other training data compositions.\n",
      "024415B_.mid: 100.00% of unique windows from the composition exist in the other training data compositions.\n",
      "011205Bsc.mid: 0.82% of unique windows from the composition exist in the other training data compositions.\n",
      "039500B_.mid: 17.59% of unique windows from the composition exist in the other training data compositions.\n",
      "002007B_.mid: 100.00% of unique windows from the composition exist in the other training data compositions.\n",
      "010306B_.mid: 4.26% of unique windows from the composition exist in the other training data compositions.\n",
      "024515B_.mid: 8.58% of unique windows from the composition exist in the other training data compositions.\n",
      "024537B_.mid: 8.65% of unique windows from the composition exist in the other training data compositions.\n",
      "000507B_.mid: 16.74% of unique windows from the composition exist in the other training data compositions.\n",
      "024444B_.mid: 21.55% of unique windows from the composition exist in the other training data compositions.\n",
      "017106B_.mid: 46.87% of unique windows from the composition exist in the other training data compositions.\n",
      "002011B_.mid: 100.00% of unique windows from the composition exist in the other training data compositions.\n",
      "000707B_.mid: 0.29% of unique windows from the composition exist in the other training data compositions.\n",
      "019406B_.mid: 2.75% of unique windows from the composition exist in the other training data compositions.\n",
      "013506B_.mid: 5.11% of unique windows from the composition exist in the other training data compositions.\n",
      "018806B_.mid: 4.95% of unique windows from the composition exist in the other training data compositions.\n",
      "025300B_.mid: 74.13% of unique windows from the composition exist in the other training data compositions.\n",
      "017606B_.mid: 0.23% of unique windows from the composition exist in the other training data compositions.\n",
      "001805Blz.mid: 89.23% of unique windows from the composition exist in the other training data compositions.\n",
      "027900B_.mid: 88.22% of unique windows from the composition exist in the other training data compositions.\n",
      "004106B_.mid: 45.01% of unique windows from the composition exist in the other training data compositions.\n",
      "008906B_.mid: 13.35% of unique windows from the composition exist in the other training data compositions.\n",
      "008405B_.mid: 1.54% of unique windows from the composition exist in the other training data compositions.\n",
      "024425B_.mid: 7.67% of unique windows from the composition exist in the other training data compositions.\n",
      "041400B_.mid: 64.40% of unique windows from the composition exist in the other training data compositions.\n",
      "015804B_.mid: 89.35% of unique windows from the composition exist in the other training data compositions.\n",
      "014406B_.mid: 2.81% of unique windows from the composition exist in the other training data compositions.\n",
      "032300B_.mid: 18.83% of unique windows from the composition exist in the other training data compositions.\n",
      "024835B3c.mid: 57.74% of unique windows from the composition exist in the other training data compositions.\n",
      "011205B_.mid: 0.89% of unique windows from the composition exist in the other training data compositions.\n",
      "Matches found between 38/404 compositions.\n"
     ]
    }
   ],
   "source": [
    "# create a hashable set for each composition in the dataset\n",
    "training_data_sets = list()\n",
    "for file in Path(training_data).glob('*.mid'):\n",
    "    # serialize file\n",
    "    sequence = serializer.serialize(file)\n",
    "    \n",
    "    # split the sequence into subsequences and create a hashable set from the composition\n",
    "    sequences, _ = sequence_utils.window([sequence], window_size=window_size)\n",
    "    hashable_set = utils.create_hashable_set(sequences)\n",
    "    \n",
    "    # transpose the sequence into all keys and create a hashable set from the composition and all its transpositions\n",
    "    sequences = sequence_utils.transpose([sequence], down=-6, up=5)\n",
    "    sequences, _ = sequence_utils.window(sequences, window_size=window_size)\n",
    "    hashable_set_trans = utils.create_hashable_set(sequences)\n",
    "    \n",
    "    # add to list of hashable sets\n",
    "    training_data_sets.append((file, hashable_set, hashable_set_trans))\n",
    "\n",
    "# compare the hashable set for each composition to the union of hashable sets for all other compositions\n",
    "counter = 0\n",
    "for f, hs, _ in training_data_sets:\n",
    "    composition_set = hs\n",
    "    remaining_set = set.union(*[hst for f2, _, hst in training_data_sets if f2 != f])\n",
    "    \n",
    "    # find the intersection of the two sets to find all matching subsequences and calculate percentage of generated subsequences that come from the training data\n",
    "    matches = composition_set.intersection(remaining_set)\n",
    "    n_matches = len(matches)\n",
    "    total = len(composition_set)\n",
    "    percentage = n_matches/total * 100\n",
    "\n",
    "    # print results, if any overlap is found\n",
    "    if percentage > 0.01:\n",
    "        counter += 1\n",
    "        print('{}: {:.2f}% of unique windows from the composition exist in the other training data compositions.'.format(f.name, percentage))\n",
    "\n",
    "print('Matches found between {}/{} compositions.'.format(counter, len(training_data_sets)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "This model is, for the most part, generating at least trivially unique sequences when sampled. The test does not take into account windows of events that might have just one or two events different.\n",
    "\n",
    "Using a higher temperature did make it more likely that generated sequences would be more unique, but there is still an element of randomness in the sampling at every temperature: for example, the lowest temperature (most predictable sampling) had one generated sequence with 0% of its windows copied from the training sequence while most other sequences had 21-38% of windows copied from the training data. Similarly, the highest temperature setting had a single generated sequence that had a relatively high percentage of windows copied from the training data, at 33.58%, while the other sequences all had percentages between 5.5-12.5%\n",
    "\n",
    "Through listening tests, it seemed that lower temperatures had a more clear musical structure, but each generated composition is unique. Sampling from the model could be another area to explore for optimal settings, by choosing the seed and temperature settings and generating multiple options using the same settings.\n",
    "\n",
    "When comparing each training data composition to the rest of the transposed dataset, there is a not insignificant amount of repetition between compositions written by Bach, indicating that some amount of repetition is inherent to the training data, and thus the compositional style, itself.\n",
    "\n",
    "This experiment raises questions that I do not currently have a clear answer to, and might be beyond the scope of this project, like what makes a composition unique, and what level of similarity is acceptable for a composition to be considered new? What would be the level of copied sequences found using a human composer who studied the training set and then tried to create a new composition in the same style?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
