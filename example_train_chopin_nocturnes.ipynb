{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model on Chopin Nocturnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.2.0-dev20200327\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from music_generator.model import MusicModel\n",
    "from music_generator.serializers.discrete_time_serializer import DiscreteTimeMidiSerializer\n",
    "import music_generator.utilities.sequence_utils as sequence_utils\n",
    "import music_generator.utilities.utils as utils\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check if CUDA and GPU are working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA and GPU Available.\n"
     ]
    }
   ],
   "source": [
    "for message in utils.check_cuda_and_gpu():\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create model\n",
    "\n",
    "The default model architecture and hyperparameters are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"music_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         45568     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 512)         1312768   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 512)         2099200   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 512)         2048      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 512)               2099200   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 356)               182628    \n",
      "=================================================================\n",
      "Total params: 6,010,212\n",
      "Trainable params: 6,006,116\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "description = 'chopin_nocturnes_transposed'\n",
    "\n",
    "model = MusicModel(\n",
    "    ckpt_dir='./training_checkpoints/{}'.format(description),\n",
    "    log_dir='./logs/{}'.format(description))\n",
    "\n",
    "model.compile()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset\n",
    "\n",
    "A folder of MIDI files are serialized into event sequences.\n",
    "\n",
    "All sequences are then transposed over a range from one whole-step down, to one whole-step up. This effectively multiplies the number of sequences by five, and similarly increases training time per epoch by about a factor of five. The result is reduced overfitting and better generated sequences. Whether the benefit outweighs the additional training time will depend on the training data and compositional style.\n",
    "\n",
    "Finally, the sequences are windowed and the last event split off to use as a label for the model to train on - predicting the next event from the given sequence.\n",
    "\n",
    "A training and validation dataset are created from the sequences and labels - the validation dataset is used in a callback to reduce the learning rate when validation loss plateaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sequences: 615714\n",
      "Validation Sequences: 32406\n"
     ]
    }
   ],
   "source": [
    "data_path = './training_data/chopin_nocturnes/'\n",
    "\n",
    "serializer = DiscreteTimeMidiSerializer()\n",
    "\n",
    "sequences = serializer.serialize_folder(data_path)\n",
    "sequences = sequence_utils.transpose(sequences, down=-2, up=2)\n",
    "sequences, labels = sequence_utils.window(sequences)\n",
    "\n",
    "dataset_train, dataset_val = sequence_utils.make_tf_datasets(sequences, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model on Dataset\n",
    "\n",
    "Progress can also be monitored via TensorBoard.\n",
    "\n",
    "The learning rate of the optimizer will be reduced when validation loss stalls.\n",
    "\n",
    "The checkpoint with the best training loss will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "try:\n",
    "    history = model.fit(dataset_train,\n",
    "                    validation_data=dataset_val,\n",
    "                    epochs=epochs,\n",
    "                    verbose=0)\n",
    "except KeyboardInterrupt as e:\n",
    "    print('\\nStopping training...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample from model\n",
    "\n",
    "Load the checkpoint from training with the lowest training loss and generate three midi files using a single chord for a seed.\n",
    "\n",
    "The resulting sequence generated is heavily influenced by the chosen seed - some experimentation is required here to find good seed choices for a particular compositional style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir = './training_checkpoints/{}'.format(description)\n",
    "model.load_checkpoint(ckpt_dir, use_latest=True)\n",
    "\n",
    "# Generate MIDI files using different seeds\n",
    "# These below represent a B-minor, G7, and A-minor chord, as well as several individual notes\n",
    "seeds = [[38, 47, 54, 62, 66],\n",
    "         [43, 55, 59, 62, 65],\n",
    "         [45, 60, 64, 69],\n",
    "         [79],\n",
    "         [95],\n",
    "         [42]]\n",
    "\n",
    "length = 1000\n",
    "\n",
    "for seed in seeds:\n",
    "    seed_string = '-'.join([str(x) for x in seed])\n",
    "    generated_sequence = model.generate_sequence(length, seed)\n",
    "    serializer.deserialize(generated_sequence, './generated_files/{}'.format(description), 'sample_{}.mid'.format(seed_string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
